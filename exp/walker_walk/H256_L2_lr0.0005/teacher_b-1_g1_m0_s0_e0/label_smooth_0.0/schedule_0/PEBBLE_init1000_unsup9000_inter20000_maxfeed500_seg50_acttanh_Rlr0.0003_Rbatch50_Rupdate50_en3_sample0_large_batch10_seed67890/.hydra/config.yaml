experiment: PEBBLE
segment: 50
activation: tanh
num_seed_steps: 1000
num_unsup_steps: 9000
num_interact: 20000
reward_lr: 0.0003
reward_batch: 50
reward_update: 50
feed_type: 0
reset_update: 100
topK: 5
ensemble_size: 3
max_feedback: 500
large_batch: 10
label_margin: 0.0
teacher_beta: -1
teacher_gamma: 1
teacher_eps_mistake: 0
teacher_eps_skip: 0
teacher_eps_equal: 0
reward_schedule: 0
num_train_steps: 500000
replay_buffer_capacity: ${num_train_steps}
eval_frequency: 10000
num_eval_episodes: 10
device: cuda
log_frequency: 10000
log_save_tb: false
save_video: false
seed: 67890
env: walker_walk
gradient_update: 1
wandb:
  enabled: true
  project: BPref_Active_Querying
  entity: Uniform Sampling
  group: Uniform_Sampling
  name: 67890
  mode: online
agent:
  name: sac
  _target_: agent.sac.SACAgent
  params:
    obs_dim: 0
    action_dim: 0
    action_range:
    - -1.0
    - 1.0
    device: ${device}
    discount: 0.99
    init_temperature: 0.1
    alpha_lr: 0.0003
    alpha_betas:
    - 0.9
    - 0.999
    actor_lr: 0.0005
    actor_betas:
    - 0.9
    - 0.999
    actor_update_frequency: 1
    critic_lr: 0.0005
    critic_betas:
    - 0.9
    - 0.999
    critic_tau: 0.005
    critic_target_update_frequency: 2
    batch_size: 128
    learnable_temperature: true
    normalize_state_entropy: true
    critic_cfg:
      _target_: agent.critic.DoubleQCritic
      obs_dim: ${..obs_dim}
      action_dim: ${..action_dim}
      hidden_dim: 256
      hidden_depth: 2
    actor_cfg:
      _target_: agent.actor.DiagGaussianActor
      obs_dim: ${..obs_dim}
      action_dim: ${..action_dim}
      hidden_dim: 256
      hidden_depth: 2
      log_std_bounds:
      - -10
      - 2
diag_gaussian_actor:
  params:
    hidden_dim: 256
    hidden_depth: 2
